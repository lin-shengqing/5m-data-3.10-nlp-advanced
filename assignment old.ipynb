{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7938f5ad",
   "metadata": {
    "id": "7938f5ad"
   },
   "source": [
    "# Assignment\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Use the following code as a starting point to load the rotten tomatoes dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49373b37",
   "metadata": {
    "id": "49373b37"
   },
   "source": [
    "**Model Application:**\n",
    "\n",
    "- Load a pre-trained sentiment analysis model from Hugging Face Transformers.\n",
    "- Apply the model to a subset of the chosen dataset (e.g., the first 1000 samples from the training set).\n",
    "- Evaluate the model's performance. You can start with qualitative analysis (inspecting predictions) and then explore quantitative metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16130beb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9276,
     "status": "ok",
     "timestamp": 1770272256803,
     "user": {
      "displayName": "Shengqing Lin",
      "userId": "08709177937519677123"
     },
     "user_tz": -480
    },
    "id": "16130beb",
    "outputId": "d2394312-5872-4658-8756-a06d1cb2ba0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets==3.6.0 in /usr/local/lib/python3.12/dist-packages (3.6.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (3.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (1.3.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (3.13.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets==3.6.0) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets==3.6.0) (0.28.1)\n",
      "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets==3.6.0) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets==3.6.0) (0.21.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets==3.6.0) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.6.0) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.6.0) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.6.0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.6.0) (2026.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==3.6.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==3.6.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==3.6.0) (2025.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (1.22.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets==3.6.0) (4.12.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets==3.6.0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets==3.6.0) (0.16.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.6.0) (1.17.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface-hub>=0.24.0->datasets==3.6.0) (8.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets==3.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b245a497",
   "metadata": {
    "executionInfo": {
     "elapsed": 16842,
     "status": "ok",
     "timestamp": 1770272273651,
     "user": {
      "displayName": "Shengqing Lin",
      "userId": "08709177937519677123"
     },
     "user_tz": -480
    },
    "id": "b245a497"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a937418b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1770272273656,
     "user": {
      "displayName": "Shengqing Lin",
      "userId": "08709177937519677123"
     },
     "user_tz": -480
    },
    "id": "a937418b",
    "outputId": "c0b2bb28-cdf0-4718-e326-4d28f86a3f3e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ded1002",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 623,
     "referenced_widgets": [
      "abca55450ee04e708c5fd76e0660f470",
      "ebdcf9bc286b45a3867563973772253f",
      "125b3e1261074dc8b3cb411036032484",
      "6963526f9a6d4004ac415188646190a2",
      "dd59962d36db4297a7dbe43bb005719a",
      "586098f7c2d9467cbe389cc7c4206715",
      "f0028e05d88a42fb839ad5515419e330",
      "10a0ec285c1f432b94c38ed0d9a98609",
      "640a92cba97b4095b2e8c960e2fd8ecc",
      "bbeb4450251547d5b116d8ec9201dd43",
      "54cfbe3834174bbc98a2a8ed1e033eeb",
      "fd8dcd2c9efd4eabb2ca61b5e652062e",
      "73f22ff2299948d2bd83e5e06edaf470",
      "243b125579844491bcb2d9dd6b095c10",
      "486bce6d07b84a528a173552ec63f91f",
      "fcf0998e959f4f1da8fc06d6571edbe2",
      "62818ddc16884ec69affc3601d4d79e6",
      "7f7c83a86321480ead31cedcbbc16cfd",
      "e288027c3e5242dba3bab761e893e7b1",
      "e796413296704929828c5bccefe25524",
      "2e91b895bcd447e1be14e80870b4e37c",
      "31f227bd2d04406fa938759b85308f5c",
      "0d48ead4cb834e99a3efdb27a99defc8",
      "6e13ab958beb4bc6bef71f389fc5abea",
      "928f93550d5e48968eadacfc2e2939bc",
      "911e539ba848454a9160df952daccfcb",
      "b8409177e0ab463eb981e4a7da5524b3",
      "d72f19c137d24d278dd04f4c426e4b45",
      "045320ce8e2a45a2b2c028e9832310b5",
      "571f684875234790a68c0fd8084dd240",
      "86c78141b2e54435924a8aa0eb5f79b9",
      "43de6c02aedc491a8bc013e5bc981e32",
      "6728fef860f84054bba86cb3888cc72c",
      "ecbd769a18da423eac8e6e6a4fd41564",
      "7d0ba6768e2d49bcaed844e03041635a",
      "4f42e7038ea7430a988225059c7501ff",
      "2426871de0f04a138a20488200771713",
      "b25c07bd300c409f9f0150ee6b325ba5",
      "d422f848cdfc42f08a14e8c477a707af",
      "2cc223de4d784c9d95452d638c4d34ae",
      "8fe82f296da344e5b934d38c8da784f3",
      "e3dbcd87ac4f4b58851bd960065cb631",
      "a2b78c37f9ba465283bdfa8a8a489937",
      "30f2d521a57b4418a9800899afcc4dac",
      "41e366d2f03b4a9392c3447cdb2b0a8a",
      "4c34b83cf8a04449b70b2d9b34bf361a",
      "4e2d91bcfff04841a30f278a405a1698",
      "ddd9a9e4f01542e5ae4357b04d5a1636",
      "06c797cb52e641ef8a1d42b5a8006b0b",
      "b5a5916fb07342b8956b138c7668fdf1",
      "441ef5a72be64494808f1c3d45d7c0de",
      "7aec538c9d8a4432b5100398b3cc2a01",
      "723d363bf71e45888df4a51aec363d15",
      "0b6462ffced84abf9f4579ded7a8ca85",
      "259595bfb54c4daaa7e2ad5f72f936a9",
      "1045da142b454d70bd54449a1bbe4fea",
      "8c73358bc15f4afd8943e03c22073bca",
      "c588ee10a9ec4f2195887e34072d3b20",
      "f41dcddb10ae41498bc1dae40a203375",
      "b67452e478be4cfa9d3070efedb80ee1",
      "d6c514185373453184ede9c78942ea94",
      "1f45da829917483798062b7c6c76aeb4",
      "7ed1ffd6acc6418dbca48746e3aa452e",
      "ce373f47548049ad906e7d46786f0f76",
      "048bba4042574df4b1410dd8a2601568",
      "3a7e67177458444da52b0740015cd072",
      "fe75ef2aa0b24040964e69f3e706968b",
      "c79498af3d104e8f84293526338900bd",
      "528602ad0a924db6ab32856b16f88dcf",
      "1802507b39694785b663c87201280831",
      "db3a51b370184987bd503c0a5cd28fe3",
      "1f52a7506d184a3fbaff86938e1cbc13",
      "1fcb77cc6cfe4bf994083740d51f46d9",
      "492c21aab38a41d0bd4251e1c3b5b0d9",
      "5b171a28c13f4300bb4625662e57c624",
      "883834f5f3634127a382b443c721fa7e",
      "6a504d1825834787b73a4d4012bb877f"
     ]
    },
    "executionInfo": {
     "elapsed": 8880,
     "status": "ok",
     "timestamp": 1770272282536,
     "user": {
      "displayName": "Shengqing Lin",
      "userId": "08709177937519677123"
     },
     "user_tz": -480
    },
    "id": "8ded1002",
    "outputId": "516e46f2-d973-438d-a8e7-8a0dc4a2f0b3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abca55450ee04e708c5fd76e0660f470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8dcd2c9efd4eabb2ca61b5e652062e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.parquet:   0%|          | 0.00/699k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d48ead4cb834e99a3efdb27a99defc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation.parquet:   0%|          | 0.00/90.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecbd769a18da423eac8e6e6a4fd41564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test.parquet:   0%|          | 0.00/92.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41e366d2f03b4a9392c3447cdb2b0a8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/8530 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1045da142b454d70bd54449a1bbe4fea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe75ef2aa0b24040964e69f3e706968b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 8530\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 1066\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 1066\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Load the Rotten Tomatoes dataset\n",
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "\n",
    "# Print the dataset information\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d811688",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1770272282546,
     "user": {
      "displayName": "Shengqing Lin",
      "userId": "08709177937519677123"
     },
     "user_tz": -480
    },
    "id": "0d811688",
    "outputId": "8ee22c9a-69d3-4a08-e237-a90fb3ad0c0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .', 'label': 1}\n",
      "{'text': 'lovingly photographed in the manner of a golden book sprung to life , stuart little 2 manages sweetness largely without stickiness .', 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "# Example: Accessing the train test split\n",
    "train_dataset = dataset[\"train\"]\n",
    "test_dataset = dataset[\"test\"]\n",
    "\n",
    "# Print the first example in the training set\n",
    "print(train_dataset[0])\n",
    "\n",
    "# Print the first example in the testing set\n",
    "print(test_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68a1ba33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177,
     "referenced_widgets": [
      "221ed98eba7f4d1b9d2ce01d69a37937",
      "95fb0d1e89ef4cee968d7b9355119dc3",
      "393fafe344454f78a62af3c9daa56c1a",
      "cb05a001eb8b48ad9bf4c1fcab982af4",
      "f50835d8fd994b5eb6afae38c838ef38",
      "4450d1a3b08245a183948a3c7e2d0f2c",
      "f86a068eca7c440883a6f2168fd9589c",
      "b180e8a17a2e4df8bc4a557c4d7702e3",
      "eff03598379e4f6bb325a94531956370",
      "db7393acf8f343dc9c330792e6a2c5df",
      "56380ef082d04c2b8fe1e60e89db54df",
      "2b53d1c28dd8400b87477947aaea2981",
      "6b5787ea45ba48b49021312573a08bcb",
      "6044ffad1cfd46c38b2a0e9bc2e97265",
      "6081a7b18a734cb29c64d705b6f227d4",
      "e0f81b99dd4049488ae569155ee5bf29",
      "cec84a2839294294aac6b92f88ee8ac6",
      "17e60894e7d34da59f06272327198c4f",
      "888ac7c3a164474abcd5a741e0b69291",
      "c41cd31fefef45f694db8ed0ac888c65",
      "f5f9c0d1a5cd4f5cb54da4cb7f268e8c",
      "cc145c1f8ffe4f318aec0ffd7b0f0de9",
      "336f8608948f46f186bdc89abc4fd470",
      "a4fe2e9f1c9543958e43d1e37883b0e9",
      "a4ed192e08784ddd9cb358ffa5a9f495",
      "279e42470440482eaf01bb818c241012",
      "abaf99f456474656b12d5fefa647e36f",
      "d86652e0f9fb489fa496861e66ee29e5",
      "2bef8057a596478f9d5378e356e325f9",
      "b05f7a861e63454e8c81574d16ee9a06",
      "af7ee3b9b4224d509b74452fec774a1a",
      "62ae02e9288d4d73bcc0b104b25453c8",
      "777f2e5f354f4bf78dfcc21564634790",
      "09e8d400df254c81bfabecbcbb7a3619",
      "3293302632f147b5bbfc5e91721308f7",
      "bff67f3d229c43f7ae3b265d6eafb4b6",
      "58771e510118491d953c9a015c08c95c",
      "2470f83e48b9428eacb5701f26f5f371",
      "049be1d208254cd79ad5859473fc9447",
      "962f69db441f4cddb60995db025aa8c1",
      "4ae24f2c32544ebd88ec3bb9a4945b2b",
      "163cb1a32cde491eaae9a222cf9d467d",
      "ce57d5d6ae5f45a89128c846bc385257",
      "224444d4e07c4410a8f5f6c3790d8153",
      "786aff4bacc746d4aad2b21c00b6ab69",
      "f3b5534bb98f41d4b6717ca2c6b302c9",
      "1daaa9c33d4f4344ad8709e122f44b3a",
      "a0ede0e586344717b2e3ec8e40c00cbe",
      "3d45382d57af45559c548a174dc60c3c",
      "8f15f377207342669a916077bebefabc",
      "3770110ee1274c72a10d2eba2fdcf018",
      "5ac070f71bc94f0f9d1b0a12cca22269",
      "8ea891bef2484f5fae792396f4e88d31",
      "e544fc47ae204a7d80f61e2346afdf1a",
      "5d96e94a01a644348ec5810767956c22"
     ]
    },
    "executionInfo": {
     "elapsed": 5159,
     "status": "ok",
     "timestamp": 1770272287705,
     "user": {
      "displayName": "Shengqing Lin",
      "userId": "08709177937519677123"
     },
     "user_tz": -480
    },
    "id": "68a1ba33",
    "outputId": "34b6a81f-4324-424c-dea6-3220cc68e471"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221ed98eba7f4d1b9d2ce01d69a37937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b53d1c28dd8400b87477947aaea2981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "336f8608948f46f186bdc89abc4fd470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09e8d400df254c81bfabecbcbb7a3619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8530 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "786aff4bacc746d4aad2b21c00b6ab69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply the model to a subset of the chosen dataset (first 1000 samples from the training set)\n",
    "subset_size = 1000\n",
    "subset = train_dataset.select(range(subset_size))\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')#lower case everything, APPLE = apple\n",
    "\n",
    "# Tokenize the dataset\n",
    "def preprocess_function(examples): #512 context window\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=True, max_length=128)\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_test_dataset = test_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7db31a31",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "c2bfe215989b4d7690dc00b44833dfe8",
      "9028db3dd40846b69990c942bd590d87",
      "6d4c423586a64831816de61176e53b95",
      "4bb3968cf172456ebf846cfded164d0c",
      "4a4dc9ef94c649caac8e893fbeb62b1d",
      "c33c480a63e84d97ba052fb344f68740",
      "0779a5c78d1a4e9c968387e738bd8d15",
      "3991a470dfeb4d74bb9c91932700185a",
      "a9beccde3ebf46f8aef0e32c350c5525",
      "c6a2d00238af4afebb6224a7d2a4d5b5",
      "671421e7cd3c4aeb8d0deb298a37324d",
      "08fa9a6d7c324406ae74ccd77f874f15",
      "6812b6b2383c4a32911fead8b64f8a14",
      "1412210569534a9a84a8ef2cf5df4608",
      "95305fd8571b4ffa8b1a13a34a7454a9",
      "991aea4245484d33ba6a7eaf4988c559",
      "7866f212e59a45d3890f5dcb1d2db46e",
      "8c582ff936f444d789c6d65c2a3758d8",
      "792dc3d59fa14c0b869f45a65a8c9a28",
      "e4e0ca94e0064a85983ddea9872c33ed",
      "08a2cb963f2c4adfaf354eec3b395ef8",
      "5ccf385f3d7749d48b9cd4c878ab51b6"
     ]
    },
    "executionInfo": {
     "elapsed": 879,
     "status": "ok",
     "timestamp": 1770272288587,
     "user": {
      "displayName": "Shengqing Lin",
      "userId": "08709177937519677123"
     },
     "user_tz": -480
    },
    "id": "7db31a31",
    "outputId": "8500df57-0e75-49fc-9c89-6ee32a3e48d6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2bfe215989b4d7690dc00b44833dfe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8530 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08fa9a6d7c324406ae74ccd77f874f15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert the labels into binary format\n",
    "def convert_labels(example):\n",
    "    if example['label'] == 1:\n",
    "        example['label'] = 1  # Positive sentiment\n",
    "    else:\n",
    "        example['label'] = 0  # Negative sentiment 0 ,1,2\n",
    "    return example\n",
    "\n",
    "binary_train_dataset = tokenized_train_dataset.map(convert_labels)\n",
    "binary_test_dataset = tokenized_test_dataset.map(convert_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2f8a602",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391,
     "referenced_widgets": [
      "0da3a508820c49cab45603b694b81b15",
      "0753f4b2f2724461b3595344cca02300",
      "f822b6ab27e24d8292383b3843591ce0",
      "d5d9ccde1c4e43e8a8800d0343802f2f",
      "7e817b1f56204c94889a9bb113cdc461",
      "c9224e02ba404400ac69b74672fa17ed",
      "d4bee9991cef465aac72942476197e7c",
      "75db8961084f46dd8ad388824570a289",
      "daeedc7920ab43d188d4062ac69049e9",
      "6919f1930f94445a9aaf449538e2987f",
      "92dc083e86be40b9a27007445508d289",
      "ea04a8ef40e443f0820a26963ee19251",
      "76689a8fa21c40c4b68955a7ed224267",
      "a8826bc0eb2b4eb1bf814a524da0cdd4",
      "723152b8fb0d4ebdacaf34109c8a60fc",
      "01031b3cb58744669acad1583297cc43",
      "8dfa6e79ae5d445585bc95e9356b8bbf",
      "2a57daacd1aa4dd189315377fd1f8440",
      "6c004486848748018979374267e5b1c5",
      "be7351918d304d12abfe1fcf025dd0ca",
      "d13293a386c14118bd604e255f294c72",
      "82eefe8f0fa64979b6bd88e6cd174ab5",
      "a080ab19a58641deb86c314b6bbfd15e",
      "6c22470213994630aad47b33d9f82f62",
      "9cd4de31c9e8487f9efadef27d46a3ef",
      "6512d25bc20844cdaed104bceb9d5a6a",
      "c2fcf2a7b1524e1d909db5e9586e8217",
      "ff3a657e92e84b0bb2f3d69e9e559c20",
      "c7d4cd50f868473c8a48d020b786c6ec",
      "969230b922f7420e9a1d7700db1c987a",
      "53f93f58a5ac4441af8730a8d2a4eb97",
      "b248344d950448fb9fcb3ca3a9082db3",
      "03e713d3111a4f8093454d86b1669968"
     ]
    },
    "executionInfo": {
     "elapsed": 5218,
     "status": "ok",
     "timestamp": 1770272293809,
     "user": {
      "displayName": "Shengqing Lin",
      "userId": "08709177937519677123"
     },
     "user_tz": -480
    },
    "id": "e2f8a602",
    "outputId": "f4bfa2a1-7dcc-4688-b0a4-8853aeebd4eb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0da3a508820c49cab45603b694b81b15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea04a8ef40e443f0820a26963ee19251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a080ab19a58641deb86c314b6bbfd15e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification LOAD REPORT from: bert-base-uncased\n",
      "Key                                        | Status     | \n",
      "-------------------------------------------+------------+-\n",
      "cls.predictions.transform.dense.weight     | UNEXPECTED | \n",
      "cls.seq_relationship.weight                | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.weight | UNEXPECTED | \n",
      "cls.seq_relationship.bias                  | UNEXPECTED | \n",
      "cls.predictions.bias                       | UNEXPECTED | \n",
      "cls.predictions.transform.dense.bias       | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED | \n",
      "classifier.bias                            | MISSING    | \n",
      "classifier.weight                          | MISSING    | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a47ab90d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223,
     "referenced_widgets": [
      "3b801d3644dd4eedbc56e403c701c1fb",
      "7a72a5784864486b9d470e475c73e54d",
      "e7eaec04fab44c85b4b0aa4d66c34c10",
      "b588bb99e4194b418157320291d2da59",
      "7fe79b35e0eb456ab9b31fe4dbef47da",
      "c59a0714c81741ebb38263501be46d5b",
      "330b510f297e4ccb9a271ff4d8321e91",
      "58c2834a44124352b5359c6295cf6157",
      "2bc65e67e5b84af390fb5470791f6fea",
      "454cea9e5ef3401a8f06cc03f5ec415c",
      "1570405d97c44f769822624b390dd87d",
      "21a30d96ddd54e3dba898f623308f441",
      "2410c03dabe8406a91800f88e2eaac0e",
      "870a5e21a4634ae4861926dadab5e476",
      "6da34ffc140b4f5a971ca6c6de2f0fd0",
      "52c2d1c6382844d7aa98715714bf6a9b",
      "6d423532267d4fc08e51f23d3c426875",
      "4da3106662184c65a6c54be4c3592b10",
      "e6b8571d2b0f4268ba800488736becd6",
      "e35d5e7974064da6b50aaa06057af299",
      "2b5cb687c2014584b6b6fa6088756765",
      "61aa5dd563d041a4b3f6ed4939b72477"
     ]
    },
    "executionInfo": {
     "elapsed": 166436,
     "status": "ok",
     "timestamp": 1770272532179,
     "user": {
      "displayName": "Shengqing Lin",
      "userId": "08709177937519677123"
     },
     "user_tz": -480
    },
    "id": "a47ab90d",
    "outputId": "c9a29127-5b72-4f38-9815-f2ab7e963c7d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`logging_dir` is deprecated and will be removed in v5.2. Please set `TENSORBOARD_LOGGING_DIR` instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='534' max='534' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [534/534 02:44, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.446665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b801d3644dd4eedbc56e403c701c1fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a30d96ddd54e3dba898f623308f441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=534, training_loss=0.4422860395595822, metrics={'train_runtime': 166.1079, 'train_samples_per_second': 51.352, 'train_steps_per_second': 3.215, 'total_flos': 338273456100360.0, 'train_loss': 0.4422860395595822, 'epoch': 1.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding # Import DataCollatorWithPadding\n",
    "\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=16, #2 GPU set up; 32\n",
    "    per_device_eval_batch_size=64,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "# Initialize the Data Collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=binary_train_dataset,\n",
    "    eval_dataset=binary_test_dataset,\n",
    "    data_collator=data_collator, # Pass the data collator here\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "HLdzPW_QeEiG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "executionInfo": {
     "elapsed": 4680,
     "status": "ok",
     "timestamp": 1770272612921,
     "user": {
      "displayName": "Shengqing Lin",
      "userId": "08709177937519677123"
     },
     "user_tz": -480
    },
    "id": "HLdzPW_QeEiG",
    "outputId": "4ca5fdde-3207-4fce-b535-39ab36fec651"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3871988356113434, 'eval_runtime': 4.6526, 'eval_samples_per_second': 229.121, 'eval_steps_per_second': 3.654, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "WMPIKjQ9esxp",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1770272773076,
     "user": {
      "displayName": "Shengqing Lin",
      "userId": "08709177937519677123"
     },
     "user_tz": -480
    },
    "id": "WMPIKjQ9esxp"
   },
   "outputs": [],
   "source": [
    "def predict_sentiment(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128).to(device)\n",
    "    outputs = model(**inputs)\n",
    "    prediction = torch.argmax(outputs.logits, dim=-1)\n",
    "    return \"positive\" if prediction.item() == 1 else \"negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "U7KsQDgRexK5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1111,
     "status": "ok",
     "timestamp": 1770273208712,
     "user": {
      "displayName": "Shengqing Lin",
      "userId": "08709177937519677123"
     },
     "user_tz": -480
    },
    "id": "U7KsQDgRexK5",
    "outputId": "0bf52785-49b0-4812-8b06-798aeee56b5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n",
      "1\n",
      "the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .\n",
      "\n",
      "positive\n",
      "1\n",
      "the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson's expanded vision of j . r . r . tolkien's middle-earth .\n",
      "\n",
      "positive\n",
      "1\n",
      "effective but too-tepid biopic\n",
      "\n",
      "positive\n",
      "1\n",
      "if you sometimes like to go to the movies to have fun , wasabi is a good place to start .\n",
      "\n",
      "positive\n",
      "1\n",
      "emerges as something rare , an issue movie that's so honest and keenly observed that it doesn't feel like one .\n",
      "\n",
      "positive\n",
      "1\n",
      "the film provides some great insight into the neurotic mindset of all comics -- even those who have reached the absolute top of the game .\n",
      "\n",
      "positive\n",
      "1\n",
      "offers that rare combination of entertainment and education .\n",
      "\n",
      "positive\n",
      "1\n",
      "perhaps no picture ever made has more literally showed that the road to hell is paved with good intentions .\n",
      "\n",
      "positive\n",
      "1\n",
      "steers turns in a snappy screenplay that curls at the edges ; it's so clever you want to hate it . but he somehow pulls it off .\n",
      "\n",
      "positive\n",
      "1\n",
      "take care of my cat offers a refreshingly different slice of asian cinema .\n",
      "\n",
      "positive\n",
      "1\n",
      "this is a film well worth seeing , talking and singing heads and all .\n",
      "\n",
      "positive\n",
      "1\n",
      "what really surprises about wisegirls is its low-key quality and genuine tenderness .\n",
      "\n",
      "positive\n",
      "1\n",
      "( wendigo is ) why we go to the cinema : to be fed through the eye , the heart , the mind .\n",
      "\n",
      "positive\n",
      "1\n",
      "one of the greatest family-oriented , fantasy-adventure movies ever .\n",
      "\n",
      "positive\n",
      "1\n",
      "ultimately , it ponders the reasons we need stories so much .\n",
      "\n",
      "positive\n",
      "1\n",
      "an utterly compelling 'who wrote it' in which the reputation of the most famous author who ever lived comes into question .\n",
      "\n",
      "negative\n",
      "1\n",
      "illuminating if overly talky documentary .\n",
      "\n",
      "positive\n",
      "1\n",
      "a masterpiece four years in the making .\n",
      "\n",
      "positive\n",
      "1\n",
      "the movie's ripe , enrapturing beauty will tempt those willing to probe its inscrutable mysteries .\n",
      "\n",
      "positive\n",
      "1\n",
      "offers a breath of the fresh air of true sophistication .\n",
      "\n",
      "positive\n",
      "1\n",
      "a thoughtful , provocative , insistently humanizing film .\n",
      "\n",
      "positive\n",
      "1\n",
      "with a cast that includes some of the top actors working in independent film , lovely & amazing involves us because it is so incisive , so bleakly amusing about how we go about our lives .\n",
      "\n",
      "positive\n",
      "1\n",
      "a disturbing and frighteningly evocative assembly of imagery and hypnotic music composed by philip glass .\n",
      "\n",
      "positive\n",
      "1\n",
      "not for everyone , but for those with whom it will connect , it's a nice departure from standard moviegoing fare .\n",
      "\n",
      "positive\n",
      "1\n",
      "scores a few points for doing what it does with a dedicated and good-hearted professionalism .\n",
      "\n",
      "positive\n",
      "1\n",
      "occasionally melodramatic , it's also extremely effective .\n",
      "\n",
      "positive\n",
      "1\n",
      "spiderman rocks\n",
      "\n",
      "positive\n",
      "1\n",
      "an idealistic love story that brings out the latent 15-year-old romantic in everyone .\n",
      "\n",
      "negative\n",
      "1\n",
      "at about 95 minutes , treasure planet maintains a brisk pace as it races through the familiar story . however , it lacks grandeur and that epic quality often associated with stevenson's tale as well as with earlier disney efforts .\n",
      "\n",
      "positive\n",
      "1\n",
      "it helps that lil bow wow . . . tones down his pint-sized gangsta act to play someone who resembles a real kid .\n",
      "\n",
      "positive\n",
      "1\n",
      "guaranteed to move anyone who ever shook , rattled , or rolled .\n",
      "\n",
      "positive\n",
      "1\n",
      "a masterful film from a master filmmaker , unique in its deceptive grimness , compelling in its fatalist worldview .\n",
      "\n",
      "negative\n",
      "1\n",
      "light , cute and forgettable .\n",
      "\n",
      "negative\n",
      "1\n",
      "if there's a way to effectively teach kids about the dangers of drugs , i think it's in projects like the ( unfortunately r-rated ) paid .\n",
      "\n",
      "positive\n",
      "1\n",
      "while it would be easy to give crush the new title of two weddings and a funeral , it's a far more thoughtful film than any slice of hugh grant whimsy .\n",
      "\n",
      "negative\n",
      "1\n",
      "though everything might be literate and smart , it never took off and always seemed static .\n",
      "\n",
      "positive\n",
      "1\n",
      "cantet perfectly captures the hotel lobbies , two-lane highways , and roadside cafes that permeate vincent's days\n",
      "\n",
      "negative\n",
      "1\n",
      "ms . fulford-wierzbicki is almost spooky in her sulky , calculating lolita turn .\n",
      "\n",
      "positive\n",
      "1\n",
      "though it is by no means his best work , laissez-passer is a distinguished and distinctive effort by a bona-fide master , a fascinating film replete with rewards to be had by all willing to make the effort to reap them .\n",
      "\n",
      "positive\n",
      "1\n",
      "like most bond outings in recent years , some of the stunts are so outlandish that they border on being cartoonlike . a heavy reliance on cgi technology is beginning to creep into the series .\n",
      "\n",
      "positive\n",
      "1\n",
      "newton draws our attention like a magnet , and acts circles around her better known co-star , mark wahlberg .\n",
      "\n",
      "positive\n",
      "1\n",
      "the story loses its bite in a last-minute happy ending that's even less plausible than the rest of the picture . much of the way , though , this is a refreshingly novel ride .\n",
      "\n",
      "positive\n",
      "1\n",
      "fuller would surely have called this gutsy and at times exhilarating movie a great yarn .\n",
      "\n",
      "positive\n",
      "1\n",
      "'compleja e intelectualmente retadora , el ladrón de orquídeas es uno de esos filmes que vale la pena ver precisamente por su originalidad . '\n",
      "\n",
      "positive\n",
      "1\n",
      "the film makes a strong case for the importance of the musicians in creating the motown sound .\n",
      "\n",
      "negative\n",
      "1\n",
      "karmen moves like rhythm itself , her lips chanting to the beat , her long , braided hair doing little to wipe away the jeweled beads of sweat .\n",
      "\n",
      "positive\n",
      "1\n",
      "gosling provides an amazing performance that dwarfs everything else in the film .\n",
      "\n",
      "positive\n",
      "1\n",
      "a real movie , about real people , that gives us a rare glimpse into a culture most of us don't know .\n",
      "\n",
      "positive\n",
      "1\n",
      "tender yet lacerating and darkly funny fable .\n",
      "\n",
      "positive\n",
      "1\n",
      "may be spoofing an easy target -- those old '50's giant creature features -- but . . . it acknowledges and celebrates their cheesiness as the reason why people get a kick out of watching them today .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test it with the first 5 train dataset\n",
    "for i in range(50):\n",
    "  print(predict_sentiment(train_dataset[i]['text']))\n",
    "  print(train_dataset[i]['label'])\n",
    "  print(train_dataset[i]['text'])\n",
    "  print()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
